{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from loadcorpus import load_corpus, load_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.Highway import Highway\n",
    "from models.lstm_pool_overlap import LSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set: ans,que,label 264416 264416 264416 264416 264416\n",
      "In validation set: ans,que,label: 39997 39997 39997 39997 39997\n"
     ]
    }
   ],
   "source": [
    "x_train_ans, x_train_ans_pos, x_train_que, \\\n",
    "x_train_que_pos, x_train_ans_overlap, x_train_que_overlap, y_train, \\\n",
    "x_valid_ans, x_valid_ans_pos, x_valid_que, \\\n",
    "x_valid_que_pos, x_valid_ans_overlap, x_valid_que_overlap, y_valid = load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = load_vocab()\n",
    "PADDINGIDX = 1\n",
    "UNKNOWNIDX = 0\n",
    "vocab['<unk>'] = UNKNOWNIDX\n",
    "vocab['<pad>'] = PADDINGIDX\n",
    "inv_vocab = {}\n",
    "inv_vocab[UNKNOWNIDX] = '<unk>'\n",
    "inv_vocab[PADDINGIDX] = '<pad>'\n",
    "\n",
    "for x in (vocab.items()):\n",
    "    inv_vocab[x[1]] = x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posLookup={}\n",
    "posLookup['<pad>'] = 0\n",
    "for x in x_valid_ans_pos:\n",
    "    for pos_tag in x:\n",
    "        posLookup[pos_tag] = posLookup.get(pos_tag, len(posLookup))\n",
    "\n",
    "for x in x_train_ans_pos:\n",
    "    for pos_tag in x:\n",
    "        posLookup[pos_tag] = posLookup.get(pos_tag, len(posLookup))\n",
    "\n",
    "for x in x_train_que_pos:\n",
    "    for pos_tag in x:\n",
    "        posLookup[pos_tag] = posLookup.get(pos_tag, len(posLookup))\n",
    "\n",
    "for x in x_valid_que_pos:\n",
    "    for pos_tag in x:\n",
    "        posLookup[pos_tag] = posLookup.get(pos_tag, len(posLookup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posLookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_freq():\n",
    "    vocab_freq = {}\n",
    "    with open('../DATA/tf_idf.data') as fin:\n",
    "        for _idx, line in enumerate(fin.readlines()):\n",
    "            line = line.split('\\t')\n",
    "            vocab_freq[_idx] = float(line[1])\n",
    "    return vocab_freq\n",
    "vocab_freq = get_vocab_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_pretrained = []\n",
    "with open('../DATA/embedding_matrix.data') as fin:\n",
    "    for line in fin.readlines():\n",
    "        embedding_pretrained.append(eval(line))\n",
    "id_mapper = eval(open('../DATA/vocab_id_matrix.data').read())\n",
    "embedding_pretrained = np.array(embedding_pretrained)\n",
    "inv_id_mapper = {}\n",
    "for x in (id_mapper.items()):\n",
    "    inv_id_mapper[x[1]] = x[0]\n",
    "inv_id_mapper[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_corpus():\n",
    "    TRAINCORPUS = [{'question': que, 'answer':ans, 'question_pos':q_pos, \\\n",
    "                    'answer_pos':a_pos, 'question_overlap': q_ovl, 'answer_overlap': a_ovl,'label':lab} \\\n",
    "                   for que, ans, q_pos, a_pos, q_ovl, a_ovl, lab in zip(x_train_que, \\\n",
    "                                                               x_train_ans, x_train_que_pos, \\\n",
    "                                                               x_train_ans_pos, \\\n",
    "                                                               x_train_que_overlap, x_train_ans_overlap, y_train)]\n",
    "    return TRAINCORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_valid_corpus():\n",
    "    que_to_anss = {}\n",
    "    for que, ans, q_pos, a_pos, q_ovl, a_ovl, lab in zip(x_valid_que, x_valid_ans, x_valid_que_pos,\\\n",
    "                                                         x_valid_ans_pos, x_valid_que_overlap,\n",
    "                                                         x_valid_ans_overlap, y_valid):\n",
    "        que_to_anss[tuple(que)] = que_to_anss.get(tuple(que), [])\n",
    "        que_to_anss[tuple(que)].append((ans, q_pos, a_pos, q_ovl, a_ovl, lab))\n",
    "    \n",
    "    VALIDCORPUS = []\n",
    "    for x in que_to_anss.items():\n",
    "        tmp = {'question':list(x[0]), 'answers':[y[0] for y in x[1]], 'question_pos':x[1][0][1], \n",
    "               'answers_pos':[y[2] for y in x[1]], 'question_overlap': [y[3] for y in x[1]], \\\n",
    "               'answers_overlap': [y[4] for y in x[1]],'labels':[y[5] for y in x[1]]}\n",
    "        VALIDCORPUS.append(tmp)\n",
    "    return VALIDCORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINCORPUS, VALIDCORPUS = prepare_train_corpus(), prepare_valid_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_Train(Dataset):\n",
    "    def __init__(self, que_len, ans_len, corpus):        \n",
    "        self.corpus = corpus\n",
    "        self.que_len = que_len\n",
    "        self.ans_len = ans_len\n",
    "        self.mapper = id_mapper\n",
    "    \n",
    "    def posToInd(self, pos_tag):\n",
    "        posLookup[pos_tag] = posLookup.get(pos_tag, len(posLookup))\n",
    "        return posLookup[pos_tag]\n",
    "        \n",
    "    def word_mapper(self, wrd):\n",
    "        if wrd in self.mapper:\n",
    "            return self.mapper[wrd]\n",
    "        else:\n",
    "            return wrd\n",
    "        \n",
    "    def __getitem__(self, index):        \n",
    "        que = torch.LongTensor(np.ones((self.que_len), dtype=np.int64))\n",
    "        ans = torch.LongTensor(np.ones((self.ans_len), dtype=np.int64))\n",
    "        que_pos = torch.LongTensor(np.zeros((self.que_len), dtype=np.int64))\n",
    "        ans_pos = torch.LongTensor(np.zeros((self.ans_len), dtype=np.int64))\n",
    "        \n",
    "        que_overlap = torch.LongTensor(np.zeros((self.que_len), dtype=np.int64))\n",
    "        ans_overlap = torch.LongTensor(np.zeros((self.ans_len), dtype=np.int64))\n",
    "        \n",
    "        txt_q = list(self.corpus[index]['question'])\n",
    "        pos_q = list(self.corpus[index]['question_pos'])\n",
    "        ovl_q = list(self.corpus[index]['question_overlap'])\n",
    "        \n",
    "        txt_a = list(self.corpus[index]['answer'])\n",
    "        pos_a = list(self.corpus[index]['answer_pos'])\n",
    "        ovl_a = list(self.corpus[index]['answer_overlap'])\n",
    "        \n",
    "        assert len(txt_q) == len(pos_q) == len(ovl_q) and len(txt_a) == len(pos_a) == len(ovl_a), \"Error!\"\n",
    "        \n",
    "        for count, (wrd, ps, indicat) in enumerate(zip(txt_q, pos_q, ovl_q)):\n",
    "            wrd = self.word_mapper(wrd)\n",
    "            que[count] = wrd\n",
    "            que_pos[count] = self.posToInd(ps)\n",
    "            que_overlap[count] = indicat\n",
    "            if count+1 >= self.que_len:\n",
    "                break\n",
    "        for count, (wrd, ps, indicat) in enumerate(zip(txt_a, pos_a, ovl_a)):\n",
    "            wrd = self.word_mapper(wrd)\n",
    "            ans[count] = wrd\n",
    "            ans_pos[count] = self.posToInd(ps)\n",
    "            ans_overlap[count] = indicat\n",
    "            if count+1 >= self.ans_len:\n",
    "                break            \n",
    "        label = torch.LongTensor([self.corpus[index]['label']])\n",
    "        return min(self.que_len, len(txt_q)), que, que_pos, que_overlap, min(self.ans_len, len(txt_a)),\\\n",
    "                    ans, ans_pos, ans_overlap, label    \n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    \n",
    "def make_weights_for_balanced_classes(samples, nclasses, PosOverNeg=1):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in samples:                                                         \n",
    "        count[item['label']] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = N/float(count[i])\n",
    "    \n",
    "    weight_per_class[1] *= PosOverNeg \n",
    "    weight = [0] * len(samples)                                              \n",
    "    for idx, val in enumerate(samples):                                          \n",
    "        weight[idx] = weight_per_class[val['label']]\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_Valid(Dataset):\n",
    "    def __init__(self, que_len, ans_len, corpus):        \n",
    "        self.corpus = corpus\n",
    "        self.que_len = que_len\n",
    "        self.ans_len = ans_len\n",
    "        self.mapper = id_mapper    \n",
    "    \n",
    "    def posToInd(self, pos_tag):\n",
    "        posLookup[pos_tag] = posLookup.get(pos_tag, len(posLookup))\n",
    "        return posLookup[pos_tag]\n",
    "        \n",
    "    def word_mapper(self, wrd):\n",
    "        if wrd in self.mapper:\n",
    "            return self.mapper[wrd]\n",
    "        else:\n",
    "            return wrd\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ques_ovl, anss, anss_pos, anss_ovl, labels = [], [], [], [], []\n",
    "        \n",
    "        que = torch.LongTensor(np.ones((self.que_len), dtype=np.int64))\n",
    "        que_pos = torch.LongTensor(np.zeros((self.que_len), dtype=np.int64))\n",
    "        \n",
    "        txt_q = list(self.corpus[index]['question'])\n",
    "        pos_q = list(self.corpus[index]['question_pos'])\n",
    "        ovl_q = list(self.corpus[index]['question_overlap'])\n",
    "        \n",
    "        txt_a = list(self.corpus[index]['answers'])\n",
    "        pos_a = list(self.corpus[index]['answers_pos'])\n",
    "        ovl_a = list(self.corpus[index]['answers_overlap'])\n",
    "        \n",
    "        \n",
    "        len_anss = torch.LongTensor(np.array([min(self.ans_len, len(a)) for a in txt_a], dtype=np.int64))\n",
    "        \n",
    "        all_labs = list(self.corpus[index]['labels'])\n",
    "        N = len(all_labs)\n",
    "        \n",
    "        assert len(txt_q) == len(pos_q), \"Error!\"\n",
    "        for _txt_a, _pos_a in zip(txt_a, pos_a):\n",
    "            assert len(_txt_a) == len(_pos_a)\n",
    "        \n",
    "        for count, (wrd, ps) in enumerate(zip(txt_q, pos_q)):\n",
    "            wrd = self.word_mapper(wrd)\n",
    "            que[count] = wrd\n",
    "            que_pos[count] = self.posToInd(ps)\n",
    "            \n",
    "            if count+1 >= self.que_len:\n",
    "                break\n",
    "                \n",
    "        \n",
    "        for _ovl_q, _txt_a, _pos_a, _ovl_a, lab in zip(ovl_q, txt_a, pos_a, ovl_a, all_labs):\n",
    "            qovl = torch.LongTensor(np.zeros((self.que_len), dtype=np.int64))\n",
    "            for count, oq in enumerate(_ovl_q):\n",
    "                qovl[count] = oq\n",
    "                if count+1 >= self.que_len:\n",
    "                    break                \n",
    "            ques_ovl.append(qovl)\n",
    "\n",
    "            aovl = torch.LongTensor(np.zeros((self.ans_len), dtype=np.int64))\n",
    "            ans = torch.LongTensor(np.ones((self.ans_len), dtype=np.int64))\n",
    "            ans_pos = torch.LongTensor(np.zeros((self.ans_len), dtype=np.int64))\n",
    "            for count, (wrd, ps, oa) in enumerate(zip(_txt_a, _pos_a, _ovl_a)):\n",
    "                wrd = self.word_mapper(wrd)\n",
    "                aovl[count] = oa\n",
    "                ans[count] = wrd\n",
    "                ans_pos[count] = self.posToInd(ps)\n",
    "                if count+1 >= self.ans_len:\n",
    "                    break\n",
    "            anss_ovl.append(aovl)\n",
    "            anss.append(ans)\n",
    "            anss_pos.append(ans_pos)\n",
    "        \n",
    "        for lab in all_labs:            \n",
    "            label = torch.LongTensor([lab])\n",
    "            labels.append(label)\n",
    "        \n",
    "        que = [que] * N\n",
    "        que_pos = [que_pos] * N\n",
    "        \n",
    "        len_ques = torch.LongTensor(np.array([min(self.que_len, len(txt_q))]*len(txt_a), dtype=np.int64))\n",
    "        len_anss, len_ques = torch.squeeze(len_anss, dim=0), torch.squeeze(len_ques, dim=0)\n",
    "        \n",
    "        def get_stacked(x):\n",
    "            return torch.squeeze(torch.stack(x))\n",
    "        que, que_pos, anss, anss_pos, labels, ques_ovl, anss_ovl =  get_stacked(que), get_stacked(que_pos), \\\n",
    "                                                get_stacked(anss), get_stacked(anss_pos), get_stacked(labels),\\\n",
    "                                                get_stacked(ques_ovl), get_stacked(anss_ovl)\n",
    "        return len_ques, que, que_pos,ques_ovl, len_anss, anss, anss_pos,anss_ovl, labels\n",
    "    def __len__(self):\n",
    "        return len(self.corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_LENGTH = 15\n",
    "ANSWER_LENGTH = 45\n",
    "TRAINSET = MyDataset_Train(QUESTION_LENGTH, ANSWER_LENGTH, TRAINCORPUS)\n",
    "VALIDSET = MyDataset_Valid(QUESTION_LENGTH, ANSWER_LENGTH, VALIDCORPUS)\n",
    "\n",
    "weights_train = make_weights_for_balanced_classes(TRAINSET.corpus, 2, PosOverNeg=1)\n",
    "weights_train = torch.DoubleTensor(weights_train)                                       \n",
    "sampler_train = torch.utils.data.sampler.WeightedRandomSampler(weights_train, len(weights_train))\n",
    "\n",
    "TRAINSET_LOADER = DataLoader(TRAINSET, batch_size=32, shuffle=False, drop_last=True, sampler=sampler_train, num_workers=5)\n",
    "VALIDSET_LOADER = DataLoader(VALIDSET, batch_size=1, shuffle=False, drop_last=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDCORPUSASTRAIN = [{'question': que, 'answer':ans, 'question_pos':q_pos, 'answer_pos':a_pos, 'label':lab} for que, ans, q_pos, a_pos, lab in zip(x_valid_que, x_valid_ans, x_valid_que_pos, x_valid_ans_pos, y_valid)]\n",
    "VALIDSETASTRAIN = MyDataset_Train(QUESTION_LENGTH, ANSWER_LENGTH, VALIDCORPUSASTRAIN)\n",
    "\n",
    "weights_valid = make_weights_for_balanced_classes(VALIDSETASTRAIN.corpus, 2)\n",
    "weights_valid = torch.DoubleTensor(weights_valid)                                       \n",
    "sampler_valid = torch.utils.data.sampler.WeightedRandomSampler(weights_valid, len(weights_valid))\n",
    "\n",
    "VALIDSETASTRAIN_LOADER = DataLoader(VALIDSETASTRAIN, batch_size=64, shuffle=False, drop_last=True, sampler=sampler_valid, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_classifier = LSTMClassifier(embedding_dim=300, hidden_dim=128,  que_len=QUESTION_LENGTH,\n",
    "                                 ans_len=ANSWER_LENGTH, pos_embedding_dim=30, posLookup=posLookup,\n",
    "                                 vocab_size=len(inv_id_mapper), PADDINGIDX=PADDINGIDX,\n",
    "                                 label_size=2, batch_size=64, use_gpu=True)\n",
    "\n",
    "lstm_classifier.word_embeddings.weight.data.copy_(torch.from_numpy(embedding_pretrained))\n",
    "lstm_classifier = lstm_classifier.cuda()\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(lstm_classifier.parameters(), lr=learning_rate)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimLoss(nn.Module):\n",
    "    # L = max(0, M + cossim(q, a_neg) - cossim(q, a_pos))\n",
    "    def __init__(self, M=0.2):\n",
    "        super(SimLoss, self).__init__()\n",
    "        self.M = M\n",
    "    def forward(self, inputs, targets):\n",
    "        batch_size = Variable(torch.ones(1).cuda() * targets.shape[0])\n",
    "        inputs = torch.squeeze(inputs)\n",
    "        loss = (-1)*targets.float()*inputs + (targets.float() - 1)*inputs + self.M\n",
    "        loss /= batch_size\n",
    "        loss = loss.sum()\n",
    "        return loss   # a single number (averaged loss over batch samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTMClassifier(nn.Module):\n",
    "#     def __init__(self, embedding_dim, hidden_dim, pos_embedding_dim, que_len, ans_len,\n",
    "#                  vocab_size, label_size, batch_size, use_gpu):\n",
    "#         super(LSTMClassifier, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.batch_size = batch_size\n",
    "#         self.use_gpu = use_gpu\n",
    "#         self.pos_embedding_dim = pos_embedding_dim\n",
    "#         self.que_len = que_len\n",
    "#         self.ans_len = ans_len\n",
    "\n",
    "#         self.pos_embeddings = nn.Embedding(len(posLookup), pos_embedding_dim, padding_idx=0)\n",
    "#         self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=PADDINGIDX)\n",
    "        \n",
    "#         self.lstm = nn.LSTM(embedding_dim+pos_embedding_dim, hidden_dim, bidirectional=True)\n",
    "        \n",
    "#         self.que_max_pooling = nn.MaxPool1d(que_len)\n",
    "#         self.ans_max_pooling = nn.MaxPool1d(ans_len)\n",
    "        \n",
    "#         self.attention_word = nn.Linear(hidden_dim*4, hidden_dim)\n",
    "#         self.tanh = nn.Tanh()\n",
    "#         self.attention_score = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(0.3)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "#         self.highway = Highway(4*hidden_dim, num_layers=1, f=nn.ReLU())\n",
    "        \n",
    "#         self.fullyconnected = nn.Linear(10*hidden_dim+2, 100)\n",
    "#         self.hidden2label_1 = nn.Linear(100, 20)\n",
    "#         self.hidden2label_2 = nn.Linear(20, label_size)\n",
    "        \n",
    "#         self.hidden2label = nn.Sequential(self.hidden2label_1, self.hidden2label_2)\n",
    "#         self.hidden = self.init_hidden()\n",
    "#         self.word_embeddings.weight.data.copy_(torch.from_numpy(embedding_pretrained))\n",
    "\n",
    "#     def init_hidden(self):\n",
    "#         h0 = Variable(torch.zeros(2, self.batch_size, self.hidden_dim).cuda())\n",
    "#         c0 = Variable(torch.zeros(2, self.batch_size, self.hidden_dim).cuda())\n",
    "#         return (h0, c0)\n",
    "\n",
    "    \n",
    "#     def forward(self, lq, que, q_pos, q_ovl, la, ans, a_pos, a_ovl):   \n",
    "#         lq, la = torch.squeeze(lq), torch.squeeze(la)  \n",
    "#         q_ovl, a_ovl = torch.squeeze(q_ovl), torch.squeeze(a_ovl)\n",
    "#         emb_que = self.word_embeddings(que)\n",
    "#         emb_ans = self.word_embeddings(ans)\n",
    "#         pos_que = self.pos_embeddings(q_pos)\n",
    "#         pos_ans = self.pos_embeddings(a_pos)\n",
    "        \n",
    "#         pos_que = pos_que.view(self.que_len, self.batch_size, -1)\n",
    "#         emb_que = emb_que.view(self.que_len, self.batch_size, -1)\n",
    "#         pos_ans = pos_ans.view(self.ans_len, self.batch_size, -1)\n",
    "#         emb_ans = emb_ans.view(self.ans_len, self.batch_size, -1)\n",
    "        \n",
    "#         emb_que = torch.cat([emb_que, pos_que], dim=-1)\n",
    "#         emb_ans = torch.cat([emb_ans, pos_ans], dim=-1)\n",
    "        \n",
    "#         vec_que, _ = self.lstm(emb_que, self.init_hidden())\n",
    "#         vec_ans, _ = self.lstm(emb_ans, self.init_hidden())\n",
    "        \n",
    "#         mask_que = torch.arange(self.que_len).expand(self.batch_size, self.que_len).cuda() < lq.float().unsqueeze(1)\n",
    "#         mask_ans = torch.arange(self.ans_len).expand(self.batch_size, self.ans_len).cuda() < la.float().unsqueeze(1)\n",
    "        \n",
    "#         vec_que = vec_que.view(-1, self.batch_size, self.que_len)\n",
    "        \n",
    "#         final_que = self.que_max_pooling(vec_que)\n",
    "#         final_que = torch.squeeze(final_que)\n",
    "#         final_que = final_que.view(self.batch_size, -1)\n",
    "        \n",
    "        \n",
    "#         vec_ans = vec_ans.view(self.ans_len, self.batch_size, -1)\n",
    "        \n",
    "#         att_scores = []\n",
    "#         ans_att_vec = []\n",
    "#         for ih, h in enumerate(vec_ans):\n",
    "#             wr_expr = torch.cat([final_que, h], dim=1)\n",
    "#             wr_expr = self.highway(wr_expr)\n",
    "#             att_vec = self.tanh(self.attention_word(wr_expr))\n",
    "#             att_score = self.attention_score(att_vec)\n",
    "#             att_scores.append(att_score)\n",
    "            \n",
    "#         att_scores = torch.stack(att_scores) # batch_size, ans_len\n",
    "#         att_scores = self.softmax(att_scores) # batch_size, ans_len\n",
    "        \n",
    "#         ans_att_vec = (vec_ans*att_scores)\n",
    "            \n",
    "#         ans_att_vec = ans_att_vec.view(-1, self.batch_size, self.ans_len)\n",
    "#         final_ans = self.ans_max_pooling(ans_att_vec)\n",
    "#         final_ans = torch.squeeze(final_ans)\n",
    "#         final_ans = final_ans.view(self.batch_size, -1)\n",
    "        \n",
    "#         diff_vec = torch.abs(final_ans - final_que)\n",
    "#         ans_coverance = torch.sum(a_ovl, dim=1).float() / (1 + la.float())\n",
    "#         que_coverance = torch.sum(q_ovl, dim=1).float() / (1 + lq.float()) # normalized coverance\n",
    "        \n",
    "#         ans_coverance = torch.unsqueeze(ans_coverance, dim=1)\n",
    "#         que_coverance = torch.unsqueeze(que_coverance, dim=1)\n",
    "        \n",
    "        \n",
    "#         vec_ans_covered = a_ovl.float().unsqueeze(2) * vec_ans.view(self.batch_size, self.ans_len, -1)\n",
    "#         vec_que_covered = q_ovl.float().unsqueeze(2) * vec_que.view(self.batch_size, self.que_len, -1)\n",
    "        \n",
    "#         vec_que_covered = vec_que_covered.view(-1, self.batch_size, self.que_len)\n",
    "#         vec_ans_covered = vec_ans_covered.view(-1, self.batch_size, self.ans_len)\n",
    "#         vec_que_covered = self.que_max_pooling(vec_que_covered)\n",
    "#         vec_ans_covered = self.ans_max_pooling(vec_ans_covered)\n",
    "#         vec_que_covered = torch.squeeze(vec_que_covered).view(self.batch_size, -1)\n",
    "#         vec_ans_covered = torch.squeeze(vec_ans_covered).view(self.batch_size, -1)\n",
    "        \n",
    "        \n",
    "#         cos_sim = nn.CosineSimilarity(dim=-1)(final_que, final_ans)\n",
    "#         cos_sim = cos_sim.view(-1, 1)\n",
    "        \n",
    "#         features = torch.cat([diff_vec, final_que, final_ans,\\\n",
    "#                               vec_que_covered, vec_ans_covered,\\\n",
    "#                               ans_coverance, que_coverance], dim=-1) # no sim\n",
    "#         denser_features = self.fullyconnected(features)\n",
    "#         # y  = cos_sim\n",
    "#         y = self.hidden2label(denser_features)\n",
    "#         return y, cos_sim\n",
    "# print(len(inv_id_mapper)+1)\n",
    "# lstm_classifier = LSTMClassifier(embedding_dim=300, hidden_dim=128,  que_len=QUESTION_LENGTH,\n",
    "#                                  ans_len=ANSWER_LENGTH, pos_embedding_dim=30,\n",
    "#                                  vocab_size=len(inv_id_mapper), \n",
    "#                                  label_size=2, batch_size=64, use_gpu=True)\n",
    "# lstm_classifier = lstm_classifier.cuda()\n",
    "# learning_rate = 0.001\n",
    "# optimizer = optim.Adam(lstm_classifier.parameters(), lr=learning_rate)\n",
    "# # loss_function = SimLoss(0.2)\n",
    "# loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_precision_f(TP, TN, FP, FN):\n",
    "    return {'recall':TP.cpu().numpy()/(TP.cpu().numpy()+FN.cpu().numpy()), \n",
    "          'precision':TP.cpu().numpy()/(TP.cpu().numpy()+FP.cpu().numpy())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_vocabulary():\n",
    "    for iter, valdata in enumerate(VALIDSET_LOADER):\n",
    "        if iter > 5:\n",
    "            break\n",
    "        q, q_pos, a, a_pos, val_labels = valdata\n",
    "        val_labels = torch.squeeze(val_labels)\n",
    "\n",
    "        q, a, val_labels = Variable(q.cuda()), Variable(a.cuda()), val_labels.cuda()\n",
    "\n",
    "        required_answers = val_labels.sum()        \n",
    "        ind_true = (val_labels==1).nonzero()\n",
    "\n",
    "        if required_answers <= 0:\n",
    "            continue\n",
    "\n",
    "        if not ind_true.shape:\n",
    "            continue\n",
    "\n",
    "        if len(val_labels.shape) == 0:\n",
    "            continue\n",
    "\n",
    "        N = val_labels.shape[0]\n",
    "        if N == 0:\n",
    "            continue\n",
    "        lstm_classifier.batch_size = len(val_labels)\n",
    "        lstm_classifier.hidden = lstm_classifier.init_hidden()\n",
    "        output = lstm_classifier(q, a)\n",
    "        output = output[-1]\n",
    "        for qs in q:\n",
    "            for wrds in qs:\n",
    "                for wrd in wrds:\n",
    "                    print(inv_vocab[inv_id_mapper[int(wrd)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_seq(seq):\n",
    "    ans = []\n",
    "    for wrd in seq:\n",
    "        ans.append(inv_vocab[inv_id_mapper[int(wrd)]])\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, VALIDSET_LOADER, input_type='probs'):\n",
    "    model.eval()\n",
    "    \n",
    "    inv_rank_sum = 0.0\n",
    "    ave_prec_sum = 0.0\n",
    "    total_questions = 0.0\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for iter, valdata in enumerate(VALIDSET_LOADER):\n",
    "        lq, q, q_pos, q_ovl, las, a, a_pos, a_ovl, val_labels = valdata\n",
    "        val_labels = torch.squeeze(val_labels)\n",
    "\n",
    "        q, a, val_labels = Variable(q.cuda()), Variable(a.cuda()), val_labels.cuda()\n",
    "        q_pos, a_pos = Variable(q_pos.cuda()), Variable(a_pos.cuda())\n",
    "        q_ovl, a_ovl = Variable(q_ovl.cuda()), Variable(a_ovl.cuda())\n",
    "        lq, las = Variable(lq.cuda()), Variable(las.cuda())\n",
    "        \n",
    "        required_answers = val_labels.sum()\n",
    "        ind_true = (val_labels==1).nonzero()\n",
    "        \n",
    "        if required_answers <= 0:\n",
    "            continue\n",
    "        \n",
    "        if not ind_true.shape:\n",
    "            continue\n",
    "        \n",
    "        if len(val_labels.shape) == 0:\n",
    "            continue\n",
    "        \n",
    "        N = val_labels.shape[0]\n",
    "        if N == 0:\n",
    "            continue\n",
    "        model.batch_size = len(val_labels)\n",
    "        model.hidden = model.init_hidden()\n",
    "        output = model(lq, q, q_pos, q_ovl, las, a, a_pos, a_ovl)\n",
    "        \n",
    "        _, predicted = torch.max(output[0].data, 1)\n",
    "        FP += ((1-val_labels)*(predicted)).sum().double()\n",
    "        FN += ((val_labels)*(1-predicted)).sum().double()\n",
    "        TP += (val_labels*predicted).sum().double()            \n",
    "        TN += ((1-val_labels)*(1-predicted)).sum().double()\n",
    "        \n",
    "        output = output[0][:,1]\n",
    "        _, ranking = torch.sort(output, dim=0, descending=True)\n",
    "        ranking = torch.squeeze(ranking)\n",
    "        \n",
    "        rank_of_true = []\n",
    "        \n",
    "        ave_p = 0.0\n",
    "        for x in ind_true:\n",
    "            rank_of_true.append(torch.squeeze((ranking == x).nonzero()))\n",
    "\n",
    "        rank_of_true = torch.stack(rank_of_true)\n",
    "        rank_of_true, _ = torch.sort(rank_of_true)\n",
    "\n",
    "        for _idx, x in enumerate(rank_of_true):\n",
    "            ave_p += _idx + 1 / (x.double() + 1)\n",
    "        \n",
    "        ave_p =  ave_p / required_answers.double()\n",
    "        \n",
    "        inv_rank_sum += 1.0 / (1 + rank_of_true[0].double())\n",
    "        ave_prec_sum += ave_p\n",
    "        total_questions += 1.0\n",
    "        \n",
    "    result = {'samples': total_questions, 'MRR': inv_rank_sum / total_questions, 'MAP': ave_prec_sum/total_questions}\n",
    "    print(get_recall_precision_f(TP, TN, FP, FN))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, TRAINSET_LOADER, VALIDSET_LOADER, runs=5, steps_per_run=100):\n",
    "    for epoch_id in range(runs):\n",
    "        num_batches = 0\n",
    "        model.train()\n",
    "\n",
    "        total_acc = 0.0\n",
    "        total_loss = 0.0\n",
    "        total = 0.0\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        FP = 0\n",
    "        FN = 0\n",
    "        for iter, traindata in enumerate(TRAINSET_LOADER): #VALIDSETASTRAIN_LOADER): # \n",
    "            if num_batches > steps_per_run:\n",
    "                break\n",
    "            num_batches += 1\n",
    "            lq, q, q_pos, q_ovl, la, a, a_pos, a_ovl, train_labels = traindata\n",
    "            train_labels = torch.squeeze(train_labels)\n",
    "\n",
    "            q, a, train_labels = Variable(q.cuda()), Variable(a.cuda()), train_labels.cuda()\n",
    "            q_pos, a_pos = Variable(q_pos.cuda()), Variable(a_pos.cuda())\n",
    "            q_ovl, a_ovl = Variable(q_ovl.cuda()), Variable(a_ovl.cuda())\n",
    "\n",
    "            lq, la = Variable(lq.cuda()), Variable(la.cuda())\n",
    "\n",
    "            model.zero_grad()\n",
    "            model.batch_size = len(train_labels)\n",
    "            model.hidden = model.init_hidden()        \n",
    "            output = model(lq, q, q_pos, q_ovl, la, a, a_pos, a_ovl)\n",
    "            # output: [prob_neg, prob_pos], score\n",
    "            loss = loss_function(output[0], Variable(train_labels))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            _, predicted = torch.max(output[0].data, 1)\n",
    "            FP += ((1-train_labels)*(predicted)).sum().double()\n",
    "            FN += ((train_labels)*(1-predicted)).sum().double()\n",
    "            TP += (train_labels*predicted).sum().double()            \n",
    "            TN += ((1-train_labels)*(1-predicted)).sum().double()\n",
    "            \n",
    "            total_acc += (predicted == train_labels).sum().double() / len(train_labels)\n",
    "            total += 1.0\n",
    "            total_loss += loss.data\n",
    "            pass\n",
    "        \n",
    "        with open('./logs/train_log.log', 'a') as fout:\n",
    "            fout.write('train:'+' '+ str(total_acc.cpu().numpy() / total) +' '+ str(total_loss.cpu().numpy() / total))\n",
    "            fout.write(str(get_recall_precision_f(TP, TN, FP, FN)))\n",
    "            fout.write('\\n')\n",
    "            fout.write(str(evaluate_model(model, VALIDSET_LOADER, input_type=\"probs\")))\n",
    "            fout.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.056173200702165006, 'precision': 0.033566433566433566}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAP': tensor(0.1954, dtype=torch.float64, device='cuda:0'),\n",
       " 'MRR': tensor(0.1773, dtype=torch.float64, device='cuda:0'),\n",
       " 'samples': 1637.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(lstm_classifier, VALIDSET_LOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(PATH):\n",
    "    loaded =  torch.load(PATH)\n",
    "    loaded = loaded.cuda()\n",
    "    loaded.eval()\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.85020479812756, 'precision': 0.1348491879350348}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f694190f128>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 737, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.7682855471035693, 'precision': 0.23589651455264105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f6941c476d8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 494, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 722, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recall': 0.6612053832650673, 'precision': 0.34855027760641577}\n"
     ]
    }
   ],
   "source": [
    "train_model(lstm_classifier, TRAINSET_LOADER, VALIDSET_LOADER, runs=3, steps_per_run=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_classifier, '../PRETRAINED/LSTMCLASSIFIER.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(lstm_classifier.state_dict(), './logs/lstm_classifier.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me_vec, us_vec, you_vec = embedding_pretrained[id_mapper[vocab['我']]],embedding_pretrained[id_mapper[vocab['美国']]],embedding_pretrained[id_mapper[vocab['你']]]\n",
    "# me_vec = lstm_classifier.word_embeddings.weight[id_mapper[vocab['我']]].cpu().detach().numpy()\n",
    "# us_vec= lstm_classifier.word_embeddings.weight[id_mapper[vocab['美国']]].cpu().detach().numpy()\n",
    "# you_vec = lstm_classifier.word_embeddings.weight[id_mapper[vocab['你']]].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid_output(lstm_classifier, VALIDSET_LOADER, indx):\n",
    "    lstm_classifier.eval()\n",
    "\n",
    "    for _idx, valdata in enumerate(VALIDSET_LOADER):\n",
    "        if not _idx == indx:\n",
    "            continue\n",
    "\n",
    "        lq, q, q_pos, q_ovl, las, a, a_pos, a_ovl, val_labels = valdata\n",
    "        val_labels = torch.squeeze(val_labels)\n",
    "\n",
    "        q, a, val_labels = Variable(q.cuda()), Variable(a.cuda()), val_labels.cuda()\n",
    "        q_pos, a_pos = Variable(q_pos.cuda()), Variable(a_pos.cuda())\n",
    "        q_ovl, a_ovl = Variable(q_ovl.cuda()), Variable(a_ovl.cuda())\n",
    "\n",
    "        lq, las = Variable(lq.cuda()), Variable(las.cuda())\n",
    "        print(q_ovl)\n",
    "        print(a_ovl)\n",
    "\n",
    "        lstm_classifier.batch_size = len(val_labels)\n",
    "        lstm_classifier.hidden = lstm_classifier.init_hidden()\n",
    "        output = lstm_classifier(lq, q, q_pos, q_ovl, las, a, a_pos, a_ovl)\n",
    "\n",
    "        output = output[0][:,1]\n",
    "        \n",
    "        _, ranking = torch.sort(output, dim=0, descending=True)\n",
    "        ranking = torch.squeeze(ranking)\n",
    "        \n",
    "        rank_of_true = []\n",
    "        ind_true = (val_labels==1).nonzero()\n",
    "        \n",
    "        ave_p = 0.0\n",
    "        for x in ind_true:\n",
    "            rank_of_true.append(torch.squeeze((ranking == x).nonzero()))\n",
    "\n",
    "        rank_of_true = torch.stack(rank_of_true)\n",
    "        rank_of_true, _ = torch.sort(rank_of_true)\n",
    "\n",
    "        for _idx, x in enumerate(rank_of_true):\n",
    "            ave_p += _idx + 1 / (x.double() + 1)\n",
    "        \n",
    "        inv_rank = 1.0 / (1 + rank_of_true[0].double())\n",
    "        \n",
    "        print('ave_p', ave_p)\n",
    "        print('inv_rank', inv_rank, rank_of_true[0].double())\n",
    "        for que, ans, t in zip(q, a, [val_labels]):\n",
    "            for qq, aa, pp, tt in zip(que, ans, output, t):\n",
    "                print(''.join(translate_seq(qq)))\n",
    "                print(''.join(translate_seq(aa)))\n",
    "                print(tt, pp)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_train_output(indx):\n",
    "    for _idx, traindata in enumerate(TRAINSET_LOADER):\n",
    "        if not _idx == indx:\n",
    "            continue\n",
    "        lstm_classifier.eval()\n",
    "        lq, q, q_pos, q_ovl, la, a, a_pos, a_ovl, train_labels = traindata\n",
    "\n",
    "        q, a, train_labels = Variable(q.cuda()), Variable(a.cuda()), train_labels.cuda()\n",
    "        q_pos, a_pos = Variable(q_pos.cuda()), Variable(a_pos.cuda())\n",
    "        q_ovl, a_ovl = Variable(q_ovl.cuda()), Variable(a_ovl.cuda())\n",
    "\n",
    "        lq, la = Variable(lq.cuda()), Variable(la.cuda())\n",
    "        \n",
    "        lstm_classifier.zero_grad()\n",
    "        lstm_classifier.batch_size = len(train_labels)\n",
    "        lstm_classifier.hidden = lstm_classifier.init_hidden()        \n",
    "        output = lstm_classifier(lq, q, q_pos, q_ovl, la, a, a_pos, a_ovl)\n",
    "\n",
    "        print(q.shape)\n",
    "        print(a.shape)\n",
    "        print(output[0].shape)\n",
    "        for que, ans, t, p, sim in zip(q, a, train_labels, output[0], output[-1]):\n",
    "                print(''.join(translate_seq(que)))\n",
    "                print(''.join(translate_seq(ans)))\n",
    "                print(t, p, sim)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 15])\n",
      "torch.Size([64, 45])\n",
      "torch.Size([64, 2])\n",
      "易方达India.代销哪些银行？<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "托管费率0<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.6394, -1.6225], device='cuda:0') tensor([ 0.1949], device='cuda:0')\n",
      "前0<pad>齐国国夏进攻哪个国家？<pad><pad><pad><pad><pad><pad>\n",
      "前India.，齐国国夏进攻鲁国。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.6050,  0.7585], device='cuda:0') tensor([ 0.2230], device='cuda:0')\n",
      "大岩山（岩）组是浙江地矿局India.地质大队？<pad>\n",
      "浙江地矿局India.地质大队，0<pad>命名。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.3428,  0.2638], device='cuda:0') tensor([ 0.1781], device='cuda:0')\n",
      "唐老鸭住在哪里？<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "尽管唐老鸭脾气暴躁、易于争吵，但是他却一直拥有一批好朋友在他的左右，更不要提那些争先恐后一睹他暴脾气和诙谐表演的忠实粉丝。<pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.9634, -2.2448], device='cuda:0') tensor([ 0.4030], device='cuda:0')\n",
      "文殊院India.？<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "据《成都县志》记载，明朝末年，India.毁于兵火，唯有0尊铁铸护戒神像和两株千<pad>古杉，历劫尚存。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.4504, -1.2845], device='cuda:0') tensor([ 0.4748], device='cuda:0')\n",
      "三亚水India.景大酒店什么时候开始二次装修？<pad><pad>\n",
      "0<pad>开业。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.8826, -2.0148], device='cuda:0') tensor([ 0.2026], device='cuda:0')\n",
      "0<pad>专家对India.0号品质综合评分是多少？<pad><pad>\n",
      "0<pad>专家品质综合评分为0分，0<pad>专家品质综合评分为0分。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-2.4947,  4.4681], device='cuda:0') tensor([ 0.2283], device='cuda:0')\n",
      "灰冠India.有多少面积的全球活动范围？<pad><pad><pad><pad>\n",
      "其全球活动范围有0,0,0平方千米（0,0,0公顷）。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.7571,  1.0173], device='cuda:0') tensor([ 0.2954], device='cuda:0')\n",
      "我很好奇流氓蛋糕店是谁创作的？<pad><pad><pad><pad>\n",
      "现在这位小麦松吉已金盆洗手，并领着一班小麦组组员India.一间西饼店，实践一直以来的梦想。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.0522, -2.3684], device='cuda:0') tensor([ 0.3150], device='cuda:0')\n",
      "我很好奇未央宫遗址在哪？<pad><pad><pad><pad><pad><pad><pad>\n",
      "称乐万岁，或曰未央”；<unk>灵殷殷，India.，延寿命，永未央”。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.5215, -1.3957], device='cuda:0') tensor([ 0.3963], device='cuda:0')\n",
      "舞台音乐剧《天龙八部》的武术指导是谁？<pad><pad><pad><pad>\n",
      "武术指导：元彬--作品《东方不败》、《新龙门客栈》<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-1.6726,  2.7616], device='cuda:0') tensor([ 0.4508], device='cuda:0')\n",
      "India.的电梯里发生了什么事件？<pad><pad><pad><pad><pad><pad>\n",
      "中式酒楼<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.7737, -1.8223], device='cuda:0') tensor([ 0.3230], device='cuda:0')\n",
      "India.被世称为？<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "闽王遣使到宾馆迎接India.，India.得知朝廷的任命，恳辞再三，审知不同意。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.5728, -3.3850], device='cuda:0') tensor([ 0.2616], device='cuda:0')\n",
      "二氟化India.在什么条件下反映？<pad><pad><pad><pad><pad><pad>\n",
      "India.在加热下反应，India.与某些India.（如三India.、五India.、三India.）在低温或室温下反应，得到不挥发的产物，蒸干后得到固体产物。<pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([ 0.2720, -0.8581], device='cuda:0') tensor([ 0.2663], device='cuda:0')\n",
      "立海大附属中学有多少学生？<pad><pad><pad><pad><pad><pad><pad>\n",
      "部长、教练/India.（India.）<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.0876, -0.5687], device='cuda:0') tensor([ 0.2596], device='cuda:0')\n",
      "0版的《天龙八部》是由谁的小说改编的？<pad>\n",
      "0<pad>版《天龙八部》改编自武侠大师金庸的同名小说，全剧以宋哲宗时代为背景，通过宋，辽，大理，西夏，吐蕃等王国之间的武林恩怨和民族矛盾，从哲学的\n",
      "tensor([ 1], device='cuda:0') tensor([-2.6330,  4.4796], device='cuda:0') tensor([ 0.2828], device='cuda:0')\n",
      "盐城市India.中学在India.India.India.举行了什么活动？<pad><pad><pad>\n",
      "India.India.India.盐城市India.中学举行对外公开教学活动0位教师开课涉及语文数学外语物理政治历史地理生物音乐体育美术等学科市区近0位教师来校听课<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-1.5731,  2.4920], device='cuda:0') tensor([ 0.3341], device='cuda:0')\n",
      "《像疯了一样》(齐秦演唱歌曲)中你\n",
      "你让我多么难堪<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([ 0.5944, -1.5735], device='cuda:0') tensor([ 0.2363], device='cuda:0')\n",
      "花右京女侍队的官方网站是什么？<pad><pad><pad><pad>\n",
      "India.－India.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.1248, -2.5012], device='cuda:0') tensor([ 0.2584], device='cuda:0')\n",
      "隆安县India.小India.前身是什么？<pad><pad><pad><pad><pad><pad><pad>\n",
      "当年五月易名隆安县India.小学。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.8436, -2.0696], device='cuda:0') tensor([ 0.2978], device='cuda:0')\n",
      "巴中高速总共投资了多少？<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "其中巴中段0公里，投资0亿元，达州段0公里，投资0亿元。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-1.5588,  2.5341], device='cuda:0') tensor([ 0.4508], device='cuda:0')\n",
      "四川三河职业学院的建筑面积有多大？<pad><pad><pad><pad>\n",
      "学院占地面积0多亩，建筑面积0万平方米，雄踞长江河岸，俯瞰万里长江。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-2.3580,  4.0108], device='cuda:0') tensor([ 0.2011], device='cuda:0')\n",
      "India.India.India.日食的下一次是什么时候？<pad><pad><pad>\n",
      "下一次日食是India.India.India.日食，该次日食亦是一次不带其他日食的日偏食。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-1.1079,  1.6409], device='cuda:0') tensor([ 0.1464], device='cuda:0')\n",
      "请问买断合同是哪一<pad>出台的？<pad><pad><pad><pad>\n",
      "0<pad>夏天，NBA为了解决各支球队越来越多<unk>高薪低能”球员的问题，专门出台了一个条款。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.4498,  0.5056], device='cuda:0') tensor([ 0.4827], device='cuda:0')\n",
      "弱碱水又叫什么？<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "提倡喝弱碱性水（也叫弱碱水或者苏打水），也有弱碱性泡腾片。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.5651,  0.6588], device='cuda:0') tensor([ 0.4334], device='cuda:0')\n",
      "India.是世界India.贵的车？<pad><pad><pad><pad><pad><pad><pad>\n",
      "India.第二贵（第一贵的为India.）的车India.，因其几乎全银色的外表和行驶时如鬼魅般无声无息而得名。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-1.4774,  2.4070], device='cuda:0') tensor([ 0.3008], device='cuda:0')\n",
      "光华牌的持有人在什么地方？<pad><pad><pad><pad><pad><pad><pad>\n",
      "持有人地址徐州市大同街八十八号&copy;lawpanel<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-1.6975,  2.8183], device='cuda:0') tensor([ 0.1703], device='cuda:0')\n",
      "上海India.国际商学院每年毕业生的就业率是多少？<pad><pad><pad><pad>\n",
      "学院重视每个学生India.的发展，为所有学生制定良好的职业生涯规划，提供规范有效的职业课程及技能实训，每<pad>毕业生就业率均达到India.以上。<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.7526,  0.8814], device='cuda:0') tensor([ 0.2581], device='cuda:0')\n",
      "《风中奇缘》中莫循的扮演者是谁？<pad><pad><pad>\n",
      "India.的多次拒绝让India.心灰意冷。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.4764, -1.2426], device='cuda:0') tensor([ 0.2233], device='cuda:0')\n",
      "泰国足球超级联赛有多少支球队？<pad><pad><pad><pad><pad><pad>\n",
      "India.(India.unitedFC)<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.4636, -1.2341], device='cuda:0') tensor([ 0.2969], device='cuda:0')\n",
      "梦洛克的品牌使命是什么？<pad><pad><pad><pad><pad><pad><pad>\n",
      "梦洛克皮鞋品牌有着其独特的品牌文化和设计理念，当中主要蕴<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.5749, -1.5067], device='cuda:0') tensor([ 0.5074], device='cuda:0')\n",
      "中国国家女子排球队在India.届世界女排锦标赛中获得多少名？\n",
      "其后，中国排球协会（以下简称中国排协）India.邀请参加0<pad>在法国举行的世界排球锦标赛（男子第0届、女子第二届）。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.7248, -1.8057], device='cuda:0') tensor([ 0.3078], device='cuda:0')\n",
      "India.minecraftpe怎么操作？<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "如果有任何问题可以去0问答、我的世界中文论坛或者MinecraftPE吧的置顶提问题提问，India.India.会热心的India.解答。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 2.0045, -4.1943], device='cuda:0') tensor([ 0.2500], device='cuda:0')\n",
      "第一颗彗星India.底被天文学家发现了什么？<pad><pad><pad><pad>\n",
      "后人为了纪念他，把这颗彗星命名为<unk>哈雷彗星”。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.9299, -2.1024], device='cuda:0') tensor([ 0.4645], device='cuda:0')\n",
      "南通India.风筝属于哪派的风筝？<pad><pad><pad><pad><pad><pad>\n",
      "India.又名南通India.，是江苏南通汉族传统手工艺品，属于南派风筝的一种。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-1.3591,  2.0907], device='cuda:0') tensor([ 0.3251], device='cuda:0')\n",
      "thewanted喜欢什么动物？<pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "星座:白羊<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.0180, -0.4059], device='cuda:0') tensor([ 0.3968], device='cuda:0')\n",
      "《娇小女孩的小夜曲》中拓海救下的女孩叫什么\n",
      "OP『India.India.』<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([-0.0318, -0.2938], device='cuda:0') tensor([ 0.2254], device='cuda:0')\n",
      "India.红丝线一般产自哪？<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "见于山箐、溪边及林下India.，海拔India.米。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([-0.5644,  0.6583], device='cuda:0') tensor([ 0.2916], device='cuda:0')\n",
      "青岛世纪长城教育咨询有限公司提供0对0面授教学吗？\n",
      "核心价值观<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.5095, -3.2517], device='cuda:0') tensor([ 0.2009], device='cuda:0')\n",
      "India.牌India.可以保存多少India.？<pad><pad><pad><pad><pad><pad><pad>\n",
      "0个月<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([ 0.2069, -0.7909], device='cuda:0') tensor([ 0.2264], device='cuda:0')\n",
      "0<pad>利物浦用多少欧元收购了苏亚雷斯？<pad><pad><pad><pad><pad>\n",
      "北京时间India.India.India.凌晨，英超利物浦俱乐部通过苏亚雷斯官方网站宣布，India.贾克斯前锋苏亚雷斯正式以0万欧元的身价转会加盟。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.2230, -0.7866], device='cuda:0') tensor([ 0.5172], device='cuda:0')\n",
      "《航空航天探险》是哪家出版社出版的？<pad><pad><pad><pad>\n",
      "出版社：黄河出版传媒集团宁夏人民出版社<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-2.6523,  4.6493], device='cuda:0') tensor([ 0.1806], device='cuda:0')\n",
      "你知道广西百色地区文联主席杨军是那个学校毕业的吗？\n",
      "0<pad>India.广西师范大学中文系。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([ 0.0933, -0.6107], device='cuda:0') tensor([ 0.3039], device='cuda:0')\n",
      "张可颐讨厌什么食物？<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "视力：正常<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.6591, -1.6040], device='cuda:0') tensor([ 0.3781], device='cuda:0')\n",
      "带锁圈的螺钉锁紧挡圈用英语怎么说？<pad><pad><pad>\n",
      "India.inChinese：India.的螺钉锁紧挡圈<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.9180,  1.3198], device='cuda:0') tensor([ 0.3364], device='cuda:0')\n",
      "《线性代数》(0<pad>中国铁道出版社出版图书)一书\n",
      "India.章矩阵<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([ 0.2686, -0.9112], device='cuda:0') tensor([ 0.2247], device='cuda:0')\n",
      "0<pad>清华大学聘请了哪位工程系教授？<pad><pad><pad><pad>\n",
      "普渡大学有\"旅游界的哈佛\"和\"美国航空航天India.\"的美誉。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.9817, -2.2315], device='cuda:0') tensor([ 0.1805], device='cuda:0')\n",
      "数字电影技术有几个阶段？<pad><pad><pad><pad><pad><pad><pad>\n",
      "参考资料<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.0210, -2.3643], device='cuda:0') tensor([ 0.2529], device='cuda:0')\n",
      "房室传导延迟是长久的还是暂时性质的呢？<pad><pad><pad>\n",
      "0每个窦性India.均能下传至心室并产生India.India.。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.6257, -3.4335], device='cuda:0') tensor([ 0.2596], device='cuda:0')\n",
      "India.·马丁内斯在India.<pad>退役的？<pad><pad><pad><pad><pad><pad>\n",
      "India.·马丁内斯（India.India.India.India.），是一位西班牙职业网球运动员，在0<pad>转职业。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.2663, -0.9238], device='cuda:0') tensor([ 0.3384], device='cuda:0')\n",
      "中考英语词语考点手册有多重？<pad><pad><pad><pad><pad><pad><pad>\n",
      "重量:0g<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.6907,  0.8950], device='cuda:0') tensor([ 0.2416], device='cuda:0')\n",
      "India.是一家什么样的公司？<pad><pad><pad><pad><pad><pad><pad>\n",
      "India.(全称India.管理咨询有限公司)，是一家以品牌策略设计为导向，集消费市场研究、品牌形象设计及推广、品牌战略及营销咨询策划、品牌知识产权注册、品牌投\n",
      "tensor([ 1], device='cuda:0') tensor([-0.7718,  1.2034], device='cuda:0') tensor([ 0.2920], device='cuda:0')\n",
      "谁知道黑莓智能手机为什么叫黑莓？<pad><pad><pad><pad><pad><pad>\n",
      "于是，在最新的黑莓India.以及最新的0上，我们看到了之前黑莓手机一直不具备的一系列华丽的功能：存储卡支持、二百万像素相机、闪光灯、India.、视频播放等一\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.8396, -1.9455], device='cuda:0') tensor([ 0.2844], device='cuda:0')\n",
      "大和吉良是什么的人物？<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "India.，0<pad>开始播出的日本动画《高达SEED》中的男主角，续集《机动战士高达SEEDDESTINY》中的主要男性角色，被称为<unk>最强的India.”。<pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.1457, -0.0311], device='cuda:0') tensor([ 0.3050], device='cuda:0')\n",
      "我想知道仙桃市第一人民医院有多少个住院科室？<pad><pad>\n",
      "医院于0<pad>挂牌成为咸宁医学院附属医院，同时还承担华中科技大学同济医学院、武汉大学医学部、长江大学医学院、三峡大学医学院、湖北民族学院医学院、仙桃职业学院等十余所\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.9803, -2.1579], device='cuda:0') tensor([ 0.3533], device='cuda:0')\n",
      "云蒙山夏季的气温是多少？<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "在India.的中部，有与周围秀丽的山光水色极不协调的India.纪泥石流遗迹；采块岩石标本观察，India.见长石或长石与石英集合体，被暗色的片状矿物（云母之类）\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.8320, -3.7868], device='cuda:0') tensor([ 0.2486], device='cuda:0')\n",
      "《战略决定成败》书中提出了多少条战略法则？<pad>\n",
      "中国企业战略导师、实战派经济学家、中国十大营销策划专家、中国十<pad>最具影响力策划专家、中国城市策划第一人、中国第一代著名策划家、中国广告、设计、企业\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.8355, -3.9254], device='cuda:0') tensor([ 0.4351], device='cuda:0')\n",
      "我想知道武汉常住人口有多少？<pad><pad><pad><pad><pad><pad>\n",
      "唐朝诗人李白在此写下<unk>黄鹤楼中India.，江城五月落梅花”，因此武汉自古又称<unk>江城”。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.6049, -3.4129], device='cuda:0') tensor([ 0.4377], device='cuda:0')\n",
      "预防低温冰冻灾害知识问答的主编India.是哪一<pad>出生的\n",
      "<unk>农家书屋”工程在解决广大农村地区<unk>买书难、借书难、看书难”问题的同时，也将让农民群众分享到改革开放带来的物质文明成果和社会主义文化发展成果\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.5873, -3.2717], device='cuda:0') tensor([ 0.2828], device='cuda:0')\n",
      "蛋白石的变种有几个？<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "有两个变种：贵蛋白石和普通蛋白石。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 1], device='cuda:0') tensor([-0.6795,  0.8682], device='cuda:0') tensor([ 0.3412], device='cuda:0')\n",
      "极致浓密胶原睫毛膏的India.是怎么样的？<pad><pad><pad><pad><pad>\n",
      "胶原蛋白：以浓密著称的活性成分水合胶原蛋白能深入睫毛内部，富含高效保湿因子——纯胶原蛋白，内含脱水胶原蛋白球，遇水即刻增大0倍体积，令睫毛瞬间充盈\n",
      "tensor([ 0], device='cuda:0') tensor([-0.0177, -0.3471], device='cuda:0') tensor([ 0.3822], device='cuda:0')\n",
      "India.定理有多少种证明方法？<pad><pad><pad><pad><pad><pad><pad>\n",
      "在公元前0至0世纪一中国学者陈子，曾经给出过任意直角三角形的India.关系即<unk>以India.India.，日India.，勾、股各乘并开方除之得斜India.。<pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 1.6493, -3.5665], device='cuda:0') tensor([ 0.3766], device='cuda:0')\n",
      "罗斯India.的India.是什么？<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "0压力变India.传感膜片是一个张紧的弹性元件，其位移随所受压而变化（对于India.压力变India.，大气压如同施加在传感膜片的低压侧一样）。<pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([ 0.4745, -1.1958], device='cuda:0') tensor([ 0.3396], device='cuda:0')\n",
      "沉香树生长在哪些地方？<pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "成活率可达India.以上。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor([ 0], device='cuda:0') tensor([-0.3449,  0.2750], device='cuda:0') tensor([ 0.1902], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "check_train_output(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  1,  0,  1,  0,  1,  1,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 1,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0],\n",
      "         [ 0,  1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,\n",
      "           0]]], device='cuda:0')\n",
      "tensor([[[ 0,  0,  0,  ...,  0,  0,  0],\n",
      "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "         [ 0,  0,  0,  ...,  0,  0,  0],\n",
      "         ...,\n",
      "         [ 0,  0,  0,  ...,  0,  1,  0],\n",
      "         [ 1,  0,  0,  ...,  0,  0,  0],\n",
      "         [ 0,  0,  0,  ...,  0,  0,  0]]], device='cuda:0')\n",
      "ave_p tensor(1., dtype=torch.float64, device='cuda:0')\n",
      "inv_rank tensor(1., dtype=torch.float64, device='cuda:0') tensor(0., dtype=torch.float64, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "宏达国际电子股份有限公司（HTCCorporation，英文旧全名HighTechComputerCorporation），常简称为HTC，是一家位于台湾桃园的科技公司。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(1, device='cuda:0') tensor(1.7282, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "India.India.India.，台湾宏达电市值超0亿美元，市值首度超过了手机巨头诺基亚。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-1.1331, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "India.India.开始市值亏损.India.HTC发布了HTCONE受到业界的喜爱。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-2.1886, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "HTC公司于India.由董事长王雪红[0]，董事暨宏达基金会董事htc长India.，与总经理兼执行长周永明所创立。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-0.9450, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "宏达国际电子股份有限公司India.India.India.India.，为威盛电子转投资的公司，是全球最大的智能手机代工和生产厂商，全球最大的WindowsMobile智能手机生产厂商之一，微软WindowsMobile\n",
      "tensor(0, device='cuda:0') tensor(-1.9138, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "旗下拥有Qtek通路品牌，dopod多普达是宏达电子公司。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-0.1463, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "宏达电现任董事长是王雪红，执行长是周永明。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-1.2799, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "India.India.，公司正式英文名称自HighTechComputerCorporation更名为HTCCorporation。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(0.3040, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "宏达电公司口号为<unk>quietlybrilliant”，常出现于公司商标上。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-1.9396, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "公司在以前知名度都不是很高，India.在0<pad>发展迅猛，现已成为全球知名手机生产商。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-2.0848, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "现在HTC系列手机搭载安卓（Android）系统和WindowsPhone系统。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-2.1888, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "另外，为强调创新精神，另一句口号<unk>HTCInnovation”也常出现于其产品以及广告上。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-2.5606, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "在HTC公司0<pad>口号变更为：谦和之中见卓越（quietlybrilliant）。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-3.0037, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "据小道新闻称，宏达（HTC）与Orange的关系最为亲密，生产出来的产品首先要保证Orange定制机的品质，质量最稳固，性能最优良，所以价钱也是最贵的。\n",
      "tensor(0, device='cuda:0') tensor(-2.2885, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "此外，宏达（HTC）的代工产品还有<unk>买断”India.，不过买断的只有极少数型号。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-1.3434, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "例如，欧洲某个运营商买断了宏达（HTC）的某个产品，那么宏达（HTC）就只为他一家生产这款产品，其他运营商只有干看的份。<pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-2.3057, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "这就说明了，为什么有的在国外上市的机型，国内的多普达没有相应的型号。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-3.3882, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "事情要追溯到PDA时期，当时还没有PPCphone，PPC和phone都分得非常清晰。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-1.8807, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "当时PDA的老大可以算是HP，但是HP本身自己India.，旗下的India.的产品从设计到生产都交给宏达（HTC）一手包办，当时宏达（HTC）就已经是全世界最大的PDA代\n",
      "tensor(0, device='cuda:0') tensor(-2.0194, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "那时正好赶上HP和COMPAQ合并，合并之后，宏达（HTC）萌生了在PDA中参加电话功效的想法，但是HP并不买单，一时之下带电话功效的PDA陷入了困境，几乎就要\n",
      "tensor(0, device='cuda:0') tensor(-3.3088, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "山穷水尽疑无路，柳暗花明又一村。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-1.8822, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "英国有名移动运营商India.看中了宏达（HTC）这款带电话功效的PDA产品，向宏达（HTC）下订单，并取名XDA，随后由宏达（HTC）代工的PPCPhone都\n",
      "tensor(0, device='cuda:0') tensor(-2.3742, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "由于这部PDA手机是新颖实物，所以当时国外India.非常好，欧洲其他运营商也都看好这款产品，纷纭向宏达（HTC）下订单，所以最终延长出了India.、Qtek、T-Mobile等\n",
      "tensor(0, device='cuda:0') tensor(-3.6404, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "宏达的运营模式还体现在一下方面：<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-3.0171, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "一、多普达和宏达（HTC）的关系：多普达是宏达（HTC）的全资子公司。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-0.3401, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "二、宏达（HTC）和<unk>双多普达”的关系：宏达（HTC）旗下有两家多普达，一家是<unk>多普达国际股份有限公司”，一家是<unk>多普达通信有限公司”。\n",
      "tensor(0, device='cuda:0') tensor(-1.0545, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "多普达国际股份有限公司总部在台湾，工厂在台湾新竹；而多普达通信有限公司总部是在上海，工厂在武汉。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-2.0194, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "三、宏达（HTC）是全球最大的windowsmobile智能手机代India.，垄断了India.的市场份额，为欧美各大电信运营供给代工智能手机业务，包含从设计到生产的India.\n",
      "tensor(0, device='cuda:0') tensor(-1.4513, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "htc<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-1.6475, device='cuda:0')\n",
      "htc的英文全名是什么，位于什么地方？<pad><pad><pad><pad>\n",
      "四、宏达（HTC）不仅代工智能手机，还是全球最大的PDA代工厂，HP、palm、DELL的PDA大多数多出自HTC之手。<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "tensor(0, device='cuda:0') tensor(-1.9529, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f551bbda438>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 494, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 722, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/jeff/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    }
   ],
   "source": [
    "check_valid_output(lstm_classifier, VALIDSET_LOADER, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
